{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "QS5vkYboMqTz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import h5py\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import tqdm\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "09yyN7h-MqT0"
      },
      "outputs": [],
      "source": [
        "# Prepare reading datasets, metadata texts\n",
        "prefix_txt = \"landmarks.\"\n",
        "prefix_img = \"coarse_tilt_aligned_face.\"\n",
        "cwd = os.getcwd()+\"/\"\n",
        "textfiles = ['fold_0_data.txt','fold_1_data.txt','fold_2_data.txt','fold_3_data.txt','fold_4_data.txt']\n",
        "\n",
        "# Since there are labels that do not match the classes stated, need to fix them\n",
        "classes = [\"(0, 2)\", \"(4, 6)\", \"(8, 12)\", \"(15, 20)\", \"(25, 32)\", \"(38, 43)\", \"(48, 53)\", \"(60, 100)\"]\n",
        "fix_dict = {'35': classes[5], '3': classes[0], '55': classes[7], '58': classes[7], \n",
        "'22': classes[3], '13': classes[2], '45': classes[5], '36': classes[5], \n",
        "'23': classes[4], '57': classes[7], '56': classes[6], '2': classes[0], \n",
        "'29': classes[4], '34': classes[4], '42': classes[5], '46': classes[6], \n",
        "'32': classes[4], '(38, 48)': classes[5], '(38, 42)': classes[5], '(8, 23)': classes[2],\n",
        " '(27, 32)': classes[4]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "DrYaHJn2MqT1"
      },
      "outputs": [],
      "source": [
        "none_count = 0\n",
        "def return_five_cross_validation(textfile):\n",
        "    global none_count\n",
        "    # one big folder list\n",
        "    folder = []\n",
        "    # start processing txt\n",
        "    with open(textfile) as text:\n",
        "        lines = text.readlines()\n",
        "    for line in lines[1:]:\n",
        "        line = line.strip().split(\"\\t\")\n",
        "        # real image path from folder\n",
        "        img_path = line[0]+\"/\"+prefix_img+line[2]+\".\"+line[1]\n",
        "        landmark_txt_path = line[0]+\"/\"+prefix_txt+line[2]+\".\"+line[1][:-3]+\"txt\"\n",
        "        if line[3] == \"None\":\n",
        "            none_count += 1\n",
        "            continue\n",
        "        else:\n",
        "            folder.append([img_path]+[landmark_txt_path]+line[3:5]+[line[-2]])\n",
        "            if folder[-1][2] in fix_dict:\n",
        "                folder[-1][2] = fix_dict[folder[-1][2]]\n",
        "    return folder\n",
        "\n",
        "\n",
        "all_folders = []\n",
        "for textfile in textfiles:\n",
        "    folder = return_five_cross_validation(textfile)\n",
        "    all_folders.append(folder)\n",
        "print(\"A sample:\", all_folders[0][0])\n",
        "print(\"No. of Pics without Age Group Label:\", none_count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "8w97NFOcMqT1"
      },
      "outputs": [],
      "source": [
        "# Methods for processing img arrays, landmarks and one-hot generation\n",
        "def read_landmark_file(filename):\n",
        "    f = open(filename, 'r')\n",
        "    points = []\n",
        "    for line in f.readlines()[2:]:\n",
        "        line = line.strip().split(\",\")[-2:]\n",
        "        points.append(np.array(line, dtype=float).astype(int))\n",
        "    f.close()\n",
        "    return points\n",
        "\n",
        "def imread(path, width, height):\n",
        "    img = cv2.imread(path)\n",
        "    return img\n",
        "\n",
        "def build_one_hot(age):\n",
        "    label = np.zeros(len(classes), dtype=int)\n",
        "    label[classes.index(age)] = 1\n",
        "    return label\n",
        "\n",
        "def resize(img, points=None, width=224, height=224):\n",
        "    # translate landmark\n",
        "    resize_ratio_x = width/img.shape[1]\n",
        "    resize_ratio_y = height/img.shape[0]\n",
        "    for i in range(len(points)):\n",
        "        points[i][0] = int(resize_ratio_x*points[i][0])\n",
        "        points[i][1] = int(resize_ratio_y*points[i][1])\n",
        "    img = cv2.resize(img, (width, height), interpolation=cv2.INTER_AREA)\n",
        "    return img, points"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "bwCYPGe9MqT1"
      },
      "outputs": [],
      "source": [
        "# image size\n",
        "width, height = 224, 224\n",
        "\n",
        "# loop for reading imgs from five folders\n",
        "all_data = []\n",
        "all_labels = []\n",
        "all_landmark_points = []\n",
        "print(\"Start reading images data...\")\n",
        "for folder in all_folders:\n",
        "    data = []\n",
        "    labels = []\n",
        "    landmark_points = []\n",
        "    for i in tqdm.tqdm(range(len(folder))):    # here using tqdm to monitor progress\n",
        "        img = imread(folder[i][0], width, height)\n",
        "        points = read_landmark_file(folder[i][1])\n",
        "        one_hot = build_one_hot(folder[i][2])\n",
        "        img, points = resize(img, points, width, height)\n",
        "        data.append(img)\n",
        "        labels.append(one_hot)\n",
        "        landmark_points.append(points)\n",
        "    all_data.append(data)\n",
        "    all_labels.append(labels)\n",
        "    all_landmark_points.append(landmark_points)\n",
        "    print(\"One folder done...\")\n",
        "print(\"All done!\")\n",
        "\n",
        "img = all_data[0][15].copy()\n",
        "for point in all_landmark_points[0][15]:\n",
        "    cv2.rectangle(img, (point[0], point[1]),(point[0]+2, point[1]+2),(255,0,0),1)\n",
        "plt.imshow(img)\n",
        "\n",
        "#plt.subplot(131),plt.imshow(all_data[0][0]),plt.title(all_labels[0][0])\n",
        "#plt.subplot(132),plt.imshow(all_data[1][0]),plt.title(all_labels[1][0])\n",
        "#plt.subplot(133),plt.imshow(all_data[2][0]),plt.title(all_labels[2][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "G550XXK8MqT2"
      },
      "outputs": [],
      "source": [
        "img = all_data[0][700].copy()\n",
        "for point in all_landmark_points[0][700]:\n",
        "    cv2.rectangle(img, (point[0], point[1]),(point[0]+2, point[1]+2),(255,0,0),1)\n",
        "plt.imshow(img)\n",
        "\n",
        "plt.subplot(131),plt.imshow(all_data[0][15]),plt.title(all_labels[0][15])\n",
        "plt.subplot(132),plt.imshow(all_data[1][0]),plt.title(all_labels[1][0])\n",
        "plt.subplot(133),plt.imshow(all_data[2][0]),plt.title(all_labels[2][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "rTSrkC2fMqT2"
      },
      "outputs": [],
      "source": [
        "# calculation of channel-wise BGR means for five folders\n",
        "b_folders = []\n",
        "g_folders = []\n",
        "r_folders = []\n",
        "n_images_folders = []\n",
        "\n",
        "# First we summarize rgb values\n",
        "for i in tqdm.tqdm(range(0, 5)):\n",
        "    b = np.zeros((height, width))\n",
        "    g = np.zeros((height, width))\n",
        "    r = np.zeros((height, width))\n",
        "    for img in all_data[i]:\n",
        "        b += img[:,:,0]\n",
        "        g += img[:,:,1]\n",
        "        r += img[:,:,2]\n",
        "    b_folders.append(b)\n",
        "    g_folders.append(g)\n",
        "    r_folders.append(r)\n",
        "    n_images_folders.append(len(all_data[i]))\n",
        "\n",
        "# Then we generate BGR mean for each cross validation situation\n",
        "# eg. When we validate folder 1, RGB mean will be generated from folder 2~5\n",
        "bgr_means = []\n",
        "for i in range(0, 5):\n",
        "    folders = [0,1,2,3,4]\n",
        "    folders.remove(i)\n",
        "    b = np.zeros((height, width))\n",
        "    g = np.zeros((height, width))\n",
        "    r = np.zeros((height, width))\n",
        "    n_image = 0\n",
        "    for folder_index in folders:\n",
        "        b += b_folders[folder_index]\n",
        "        g += g_folders[folder_index]\n",
        "        r += r_folders[folder_index]\n",
        "        n_image += n_images_folders[folder_index]\n",
        "    bgr_means.append(np.array([np.mean(b/n_image), np.mean(g/n_image), np.mean(r/n_image)]))\n",
        "    \n",
        "print(\"BGR Means Array:\", bgr_means)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "AV8m0qc8MqT2"
      },
      "outputs": [],
      "source": [
        "# Generate mean image for each cross validation situation\n",
        "# eg. When we validate folder 1, RGB mean will be generated from folder 2~5\n",
        "mean_imgs = []\n",
        "for i in tqdm.tqdm(range(0, 5)):\n",
        "    folders = [0,1,2,3,4]\n",
        "    folders.remove(i)\n",
        "    mean_image = np.zeros(all_data[0][0].shape)\n",
        "    n_image = 0\n",
        "    for folder_index in folders:\n",
        "        for img in all_data[folder_index]:\n",
        "            mean_image += img\n",
        "        n_image += n_images_folders[folder_index]\n",
        "    mean_imgs.append(np.array(mean_image/n_image, dtype=np.uint8))\n",
        "\n",
        "print(mean_imgs[0].shape, mean_imgs[1].dtype)\n",
        "plt.subplot(121),plt.imshow(mean_imgs[0])\n",
        "plt.subplot(122),plt.imshow(mean_imgs[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "z6nQ-zbAMqT3"
      },
      "outputs": [],
      "source": [
        "# Generate h5py dataset\n",
        "with h5py.File('faces_dataset.h5', 'w') as f:\n",
        "    for i in range(0, 5):\n",
        "        dset_face = f.create_dataset(\"data_\"+str(i+1), data = np.array(all_data[i]))\n",
        "        dset_headers = f.create_dataset('labels_'+str(i+1), data = np.array(all_labels[i]))\n",
        "    dst_bgr_means = f.create_dataset('bgr_means', data = np.array(bgr_means))\n",
        "    #dst_mean_imgs = f.create_dataset('mean_imgs', data = np.array(mean_imgs))\n",
        "print(\"Generation Success!\")\n",
        "\n",
        "with h5py.File('faces_landmark.h5', 'w') as f:\n",
        "    for i in range(0, 5):\n",
        "        dset_landmark = f.create_dataset(\"landmark_\"+str(i+1), data = np.array(all_landmark_points[i]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "dGcxC-YnMqT3"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}